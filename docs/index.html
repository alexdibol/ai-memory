<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />

  <title>AI Memory — Long Context, Long Memory Under Governance</title>
  <meta name="description" content="AI Memory: governance-first laboratories for long-context memory systems. One book and three Colab-style notebooks implementing mechanisms for context retention, retrieval, and temporal reasoning with auditable artifacts. Built for MBA/MFin cohorts and professional finance practitioners." />

  <style>
    :root{
      --bg:#07080d;
      --panel:#0f1220;
      --panel2:#141836;
      --text:#eef0ff;
      --muted:#b8bddb;
      --border:rgba(255,255,255,0.09);
      --accent:#7aa2ff;
      --accent2:#6ee7c8;
      --warn:#ffd27a;
      --shadow:0 18px 60px rgba(0,0,0,0.45);
      --danger:#ff7a7a;
    }
    *{box-sizing:border-box;}
    body{
      margin:0;
      background:
        radial-gradient(900px 600px at 18% 12%, rgba(122,162,255,0.14), transparent 60%),
        radial-gradient(800px 600px at 82% 88%, rgba(110,231,200,0.10), transparent 60%),
        var(--bg);
      color:var(--text);
      font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Arial;
      line-height:1.75;
    }
    a{color:var(--accent);text-decoration:none;}
    a:hover{color:var(--accent2);text-decoration:underline;}
    .container{max-width:1180px;margin:0 auto;padding:48px 22px 96px;}

    h1{font-size:40px;margin:0 0 14px;text-transform:uppercase;letter-spacing:0.02em;}
    h2{font-size:30px;margin:64px 0 14px;}
    h3{font-size:19px;margin:0 0 10px;}
    p{color:var(--muted);max-width:110ch;}

    .hero{
      padding:44px;
      border-radius:24px;
      background:linear-gradient(180deg, rgba(20,24,54,0.95), rgba(15,18,32,0.9));
      border:1px solid var(--border);
      box-shadow:var(--shadow);
    }

    .pill{
      display:inline-block;
      padding:8px 12px;
      border-radius:999px;
      border:1px solid rgba(122,162,255,0.22);
      background:rgba(122,162,255,0.08);
      color:var(--muted);
      font-size:12px;
      font-weight:800;
      letter-spacing:0.06em;
      text-transform:uppercase;
      margin-top:10px;
    }

    .callout{
      margin-top:26px;
      padding:22px;
      border-radius:20px;
      background:linear-gradient(135deg, rgba(122,162,255,0.08), rgba(110,231,200,0.06));
      border:1px solid rgba(122,162,255,0.22);
      color:var(--muted);
    }

    .callout strong{color:var(--text);}

    .grid{
      display:grid;
      grid-template-columns:repeat(auto-fit,minmax(280px,1fr));
      gap:20px;
      margin-top:28px;
    }

    .card{
      padding:22px;
      border-radius:20px;
      background:var(--panel2);
      border:1px solid var(--border);
      box-shadow:0 12px 34px rgba(0,0,0,0.32);
      display:flex;
      flex-direction:column;
      min-height:250px;
    }

    .card p{margin:0;}
    .card p + p{ margin-top:10px; }

    .card a{
      display:inline-block;
      margin-top:auto;
      padding-top:14px;
      font-weight:800;
      letter-spacing:0.03em;
      text-transform:uppercase;
      font-size:12px;
    }

    .reviewbox{
      margin-top:28px;
      padding:28px;
      border-radius:22px;
      border:1px solid rgba(255,210,122,0.35);
      background:linear-gradient(135deg, rgba(255,210,122,0.07), rgba(122,162,255,0.06));
    }

    .stars{
      color:var(--warn);
      font-size:20px;
      font-weight:900;
      letter-spacing:0.12em;
      margin-bottom:14px;
    }

    .dangerbox{
      margin-top:18px;
      padding:18px;
      border-radius:18px;
      border:1px solid rgba(255,122,122,0.32);
      background:linear-gradient(135deg, rgba(255,122,122,0.08), rgba(122,162,255,0.05));
      color:var(--muted);
    }

    .kpi{
      display:flex;
      flex-wrap:wrap;
      gap:10px;
      margin-top:18px;
    }
    .tag{
      display:inline-flex;
      align-items:center;
      gap:8px;
      padding:8px 10px;
      border-radius:999px;
      border:1px solid var(--border);
      background:rgba(255,255,255,0.04);
      color:var(--muted);
      font-size:12px;
      font-weight:700;
      letter-spacing:0.02em;
      white-space:nowrap;
    }
    .dot{
      width:8px;height:8px;border-radius:999px;background:var(--accent);
      box-shadow:0 0 0 3px rgba(122,162,255,0.10);
      flex:0 0 auto;
    }
    .dot2{ background:var(--accent2); box-shadow:0 0 0 3px rgba(110,231,200,0.10); }
    .dot3{ background:var(--warn); box-shadow:0 0 0 3px rgba(255,210,122,0.10); }

    footer{
      margin-top:96px;
      padding-top:32px;
      border-top:1px solid var(--border);
      font-size:13px;
      color:var(--muted);
      text-align:center;
    }

    code.inline{
      padding:2px 6px;
      border-radius:8px;
      border:1px solid var(--border);
      background:rgba(255,255,255,0.04);
      color:var(--text);
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", "Courier New", monospace;
      font-size:0.95em;
    }
  </style>
</head>

<body>
<main class="container">

<!-- INTRODUCTION -->
<section class="hero">
  <h1>AI Memory</h1>
  <div class="pill">Long Context · Long Memory · Governance-First Mechanisms</div>

  <p>
    <strong>AI Memory</strong> is a governed laboratory for building and reviewing <strong>long-context memory systems</strong>:
    how models carry state across long documents, how retrieval competes with recency, how “relevant” becomes a liability
    under dilution, and how a professional team can supervise memory behavior without relying on vibes.
  </p>

  <p>
    The objective is not “bigger context.” Bigger context is often just a larger room for the model to misplace your keys.
    The objective is <strong>controlled memory</strong>: explicit state, explicit update rules, bounded retrieval, and
    <strong>artifacts that make a run reconstructable</strong>. If a system cannot explain what it remembered,
    what it forgot, and why it selected what it selected, then “long context” is a marketing feature, not an engineering property.
  </p>

  <p>
    This repository is designed for <strong>MBA / Master of Finance cohorts</strong> and <strong>professional finance practitioners</strong>
    who need mechanism clarity under constraint. In finance and governance-heavy settings, the failure mode is predictable:
    long documents produce confident synthesis that quietly mixes facts, assumptions, and stale context. This lab makes that
    failure measurable and reviewable.
  </p>

  <div class="kpi">
    <span class="tag"><span class="dot"></span>Explicit state &amp; update rules</span>
    <span class="tag"><span class="dot2"></span>Bounded retrieval &amp; termination</span>
    <span class="tag"><span class="dot3"></span>Audit artifacts (manifests, logs, outputs)</span>
  </div>

  <div class="callout">
    <strong>Positioning:</strong> AI Memory is not a “chatbot enhancement.” It is a governed approach to
    long-context behavior: selection, retention, and temporal consistency as a controlled system.
  </div>

  <div class="dangerbox">
    <strong>Professional warning:</strong> long context can increase persuasion while decreasing correctness.
    The lab assumes outputs are <strong>Not verified</strong> until independently reviewed and replicated.
  </div>
</section>

<!-- QUICK LINKS -->
<section>
  <h2>Repository Layout (Where Things Live)</h2>

  <p>
    The materials are intentionally simple to locate. The book provides the interpretive layer; the notebooks implement
    the mechanisms end-to-end. In GitHub terms, you will spend most of your time in:
    <code class="inline">/book</code>, <code class="inline">/notebooks</code>, and <code class="inline">/docs</code>.
  </p>

  <div class="grid">
    <div class="card">
      <h3>Book (PDF)</h3>
      <p>
        The conceptual spine: what “memory” means in long context, why it fails, how retrieval creates new risks,
        and how governance turns memory into a reviewable subsystem instead of a narrative generator.
      </p>
      <a href="https://github.com/alexdibol/ai-memory/blob/main/book/AI%20MEMORY%20BOOK.pdf" target="_blank" rel="noopener">
        Read Book (PDF)
      </a>
    </div>

    <div class="card">
      <h3>Notebooks</h3>
      <p>
        Three governed laboratories implementing the book’s mechanisms. Each notebook is designed as a complete run:
        inputs → memory/retrieval logic → diagnostics → stage-gate decision → artifacts.
      </p>
      <a href="https://github.com/alexdibol/ai-memory/tree/main/notebooks" target="_blank" rel="noopener">
        Browse Notebooks Folder
      </a>
    </div>

   
  </div>

  <div class="callout">
    <strong>Operating rule:</strong> treat notebook outputs as governed experimental artifacts.
    They are intended to be challenged, replicated, and reviewed—not accepted because they read well.
  </div>
</section>

<!-- BOOK -->
<section>
  <h2>The Book</h2>

  <p>
    The book is not optional context; it is the control layer for interpretation. A notebook can produce coherent output
    even when memory behavior is failing. The book names the failure modes and forces a professional posture:
    <strong>separate facts from assumptions</strong>, treat retrieval as a constrained selection problem, and insist on
    artifacts that let someone else reconstruct what happened.
  </p>

  <div class="grid">
    <div class="card">
      <h3>AI Memory Book — Long Context, Long Memory</h3>
      <p>
        A governance-first mini-book that frames long-context memory as a system: state, update rules, retrieval,
        temporal consistency, and supervision. The goal is to turn “memory” from a vague capability into a
        reviewable mechanism with explicit boundaries.
      </p>
      <p>
        If you are presenting this work to a committee, the book is your guardrail: it makes the claims precise,
        and it makes the limits non-negotiable.
      </p>
      <a href="https://github.com/alexdibol/ai-memory/blob/main/book/AI%20MEMORY%20BOOK.pdf" target="_blank" rel="noopener">
        Read Book (PDF)
      </a>
    </div>
  </div>

  <div class="callout">
    <strong>Governance premise:</strong> “Memory” is a liability unless it is bounded, logged, and reviewable.
    This repository treats retrieval and long context as <em>controlled operations</em>, not as magic.
  </div>
</section>

<!-- NOTEBOOKS -->
<section>
  <h2>The Three Chapter Notebooks (Governed Colab Laboratories)</h2>

  <p>
    The notebooks live in <code class="inline">/notebooks</code> and are named <code class="inline">CHAPTER 1.ipynb</code>,
    <code class="inline">CHAPTER 2.ipynb</code>, and <code class="inline">CHAPTER 3.ipynb</code>.
    Each chapter is designed to make one core mechanism legible, then stress it until the failure mode is obvious.
  </p>

  <div class="grid">

    <div class="card">
      <h3>Chapter 1 — Memory as State (Write, Keep, Forget)</h3>
      <p>
        Memory begins as an explicit state problem: what gets written, what gets kept, what gets overwritten, and what is
        intentionally discarded. This chapter frames long context as a control loop with explicit state transitions rather than
        “the model remembers things.”
      </p>
      <p>
        The mechanism objective is to make memory update rules observable: you should be able to point to the state and explain
        why a later answer did (or did not) reference earlier material.
      </p>
      <a href="https://github.com/alexdibol/ai-memory/blob/main/notebooks/CHAPTER%201.ipynb" target="_blank" rel="noopener">
        Open Notebook
      </a>
    </div>

    <div class="card">
      <h3>Chapter 2 — Retrieval is Selection Under Constraint</h3>
      <p>
        Retrieval is not truth; it is a selection mechanism competing against recency, similarity, and context budget.
        This chapter treats retrieval as a governed gate: what evidence is admitted, how it is ranked, how it is truncated,
        and how the system signals uncertainty when the evidence is thin.
      </p>
      <p>
        The mechanism objective is to prevent “citation theater” and to make selection behavior auditable.
      </p>
      <a href="https://github.com/alexdibol/ai-memory/blob/main/notebooks/CHAPTER%202.ipynb" target="_blank" rel="noopener">
        Open Notebook
      </a>
    </div>

    <div class="card">
      <h3>Chapter 3 — Temporal Consistency (Long Memory Without Drift)</h3>
      <p>
        Long memory fails when time is implicit: older context becomes stale, new context gets blended without provenance,
        and the system “helpfully” resolves contradictions by inventing glue. This chapter focuses on temporal discipline:
        memory snapshots, conflict detection, and escalation rules when the record cannot be reconciled safely.
      </p>
      <p>
        The mechanism objective is to make drift visible and to enforce human review at the right boundary.
      </p>
      <a href="https://github.com/alexdibol/ai-memory/blob/main/notebooks/CHAPTER%203.ipynb" target="_blank" rel="noopener">
        Open Notebook
      </a>
    </div>

  </div>

  <div class="callout">
    <strong>Notebook invariant:</strong> explicit memory state · bounded retrieval · deterministic structure (where applicable) ·
    artifacts per run · outputs explicitly labeled <strong>verification_status="Not verified"</strong> until reviewed.
  </div>
</section>

<!-- INDEPENDENT ASSESSMENT -->
<section>
  <h2>Independent Assessment (Non-Authoritative)</h2>

  <div class="reviewbox">
    <div class="stars">⭐⭐⭐⭐⭐</div>

    <p>
      AI Memory is unusually serious about what long context actually means in professional settings.
      Instead of treating “more tokens” as a capability, it treats memory as a governed subsystem:
      explicit state, explicit selection, explicit failure modes, and a posture of auditability rather than persuasion.
    </p>

    <p>
      The strongest contribution is the way it reframes retrieval: not as a convenience feature, but as the core risk surface.
      Selection under constraint is where hallucination, dilution, and narrative glue appear—and the chapter structure makes those
      behaviors legible enough to supervise.
    </p>

    <p>
      <strong>Disclosure:</strong> This assessment is generated commentary, not certification or endorsement.
      Long-context systems can sound correct while being wrong. Treat all outputs as <strong>Not verified</strong>
      until independently replicated and reviewed.
    </p>
  </div>
</section>

<!-- DISCLAIMERS -->
<section>
  <h2>Licensing, Governance &amp; AI Use Disclosure</h2>

  <div class="callout">
    <p>
      <strong>Copyright © Alejandro Reynoso.</strong> All original text, structure, and pedagogical design remain
      the intellectual property of the author.
    </p>

    <p>
      <strong>License:</strong> MIT License (unless otherwise noted). You may use, copy, modify, and distribute this material
      provided that copyright and license notices are preserved.
    </p>

    <p>
      <strong>AI use disclosure:</strong> Generative AI tools may be used to assist drafting and editing.
      Conceptual design, governance decisions, validation, and final approval remain human-led.
      Responsibility for interpretation and use remains with the user.
    </p>

    <p>
      <strong>Educational use only:</strong> This material does not constitute investment, legal, accounting,
      or compliance advice. Any professional application requires independent verification and qualified human review.
    </p>
  </div>
</section>

<footer>
  AI Memory · Long Context, Long Memory Under Governance · Mechanism-First, Reviewable Systems
</footer>

</main>
</body>
</html>

